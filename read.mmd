# Proyecto: Arrastrar y Soltar Virtual con Seguimiento de Mano

Este proyecto implementa un sistema interactivo de "drag & drop" (arrastrar y soltar) utilizando Python, OpenCV y MediaPipe. Permite al usuario mover un objeto virtual (cuadro) en la pantalla mediante gestos de la mano capturados en tiempo real desde la cámara web.

---

## Objetivos del Proyecto

- Detectar la mano del usuario en tiempo real usando la cámara.
- Reconocer el gesto de “agarre” (al juntar el índice y el pulgar).
- Mover un cuadro virtual en pantalla siguiendo el movimiento de la mano.
- Soltar el objeto al separar los dedos.
- Visualizar todo el proceso con una interfaz gráfica simple y moderna.

---

## Tecnologías Utilizadas

- **Python 3.10**
- **OpenCV**: para captura de video y renderizado.
- **MediaPipe**: para detección y seguimiento de manos.
- **NumPy**: para operaciones matemáticas (cálculo de distancia).

---

## ¿Cómo Funciona?

1. Se inicializa la cámara con OpenCV y se activa el detector de manos de MediaPipe.
2. Se identifican las coordenadas del **índice (punto 8)** y el **pulgar (punto 4)**.
3. Se calcula la distancia entre ellos:
   - Si están **a menos de 40 píxeles** → se interpreta como un **agarre**.
   - Si están separados → se interpreta como un **soltar**.
4. Si el gesto de agarre ocurre dentro de los límites del cuadro virtual, se considera que el usuario está arrastrando el objeto.
5. El cuadro se mueve con la posición del índice mientras se mantiene el gesto de agarre.
6. Se dibuja un cuadro semi-transparente con borde blanco para una visualización clara y estética.

---

## Interfaz

- Un solo cuadro aparece en la pantalla.
- Se vuelve **verde** cuando se está agarrando.
- Se mueve suavemente con el dedo mientras está siendo agarrado.
- Presionar `ESC` cierra la ventana.